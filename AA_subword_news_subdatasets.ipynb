{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AA_subword_news_subdatasets.ipynb","provenance":[],"authorship_tag":"ABX9TyNnfXcFdlSH1ocP63qUddeH"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"WkzXUUJt0VRP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":207},"executionInfo":{"status":"ok","timestamp":1600703841496,"user_tz":-360,"elapsed":10141,"user":{"displayName":"ibrahim al azhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcTQUbimVsO7p7wRuyYZSNKei7erJoiKLzcwQ3eoY=s64","userId":"00085534427974934913"}},"outputId":"844eaa25-55cb-4ad4-de6e-1373c2809ce2"},"source":["!pip install sentencepiece\n","!pip install tf_sentencepiece"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 2.9MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.91\n","Collecting tf_sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/a5/16123d662ebeb087552c39c895e9ec6239fb828e236d95fdf67b20907b27/tf_sentencepiece-0.1.90-py2.py3-none-manylinux1_x86_64.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 2.7MB/s \n","\u001b[?25hInstalling collected packages: tf-sentencepiece\n","Successfully installed tf-sentencepiece-0.1.90\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uXd26PqzYcAa","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600703860008,"user_tz":-360,"elapsed":8459,"user":{"displayName":"ibrahim al azhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcTQUbimVsO7p7wRuyYZSNKei7erJoiKLzcwQ3eoY=s64","userId":"00085534427974934913"}}},"source":["from fastai import *\n","from fastai.text import *\n","\n","import re\n","import sentencepiece as spm"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"bTPwtny1YweO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600703977099,"user_tz":-360,"elapsed":81603,"user":{"displayName":"ibrahim al azhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcTQUbimVsO7p7wRuyYZSNKei7erJoiKLzcwQ3eoY=s64","userId":"00085534427974934913"}},"outputId":"f429af9e-8a96-4b38-f4a1-494e4e3ec04d"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SCN2vjDgYxdz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600704011668,"user_tz":-360,"elapsed":3422,"user":{"displayName":"ibrahim al azhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcTQUbimVsO7p7wRuyYZSNKei7erJoiKLzcwQ3eoY=s64","userId":"00085534427974934913"}}},"source":["# don't need for run\n","import os # set the all path where store the datasets\n","path = Path(os.getcwd())\n","path = path/'gdrive'/'My Drive' # declare the path\n","# news=path/'Thesis Data'/'full doc csv'\n","aa=path/'Thesis Data'/'Our dataset' # declare the rest of path as 'aa'\n","# aa=path/'Thesis Data'/'Our dataset'\n","# aa2=path/'Thesis Data'/'AA dataset'\n","# char=path/'Thesis Data'/'char-ulm'"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q0NsqYvUZM_T","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600704085560,"user_tz":-360,"elapsed":2092,"user":{"displayName":"ibrahim al azhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcTQUbimVsO7p7wRuyYZSNKei7erJoiKLzcwQ3eoY=s64","userId":"00085534427974934913"}}},"source":["vocab = \" !\\\"#$%&'()*+,-./0123456789:;=<>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]^_`abcdefghijklmnopqrstuvwxyz{|}~¥§©±ঃঅআইঈউঊঋএঐওঔকখগঘঙচছজঝঞটঠডঢণতথদধনপফবভমযরলশষসহ়ািীুূৃেৈোৌ্ৎৗড়ঢ়য়০১২৩৪৫৬৭৮৯৷‘’‚“”‪™−√∝∞\"  # set all things in vocab "],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"rOuJBagzZfWq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600704170890,"user_tz":-360,"elapsed":2305,"user":{"displayName":"ibrahim al azhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcTQUbimVsO7p7wRuyYZSNKei7erJoiKLzcwQ3eoY=s64","userId":"00085534427974934913"}}},"source":["vocab_size = 30000\n","model_prefix = 'sp'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"iMUkUAWOZ0Ix","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1600704192254,"user_tz":-360,"elapsed":3589,"user":{"displayName":"ibrahim al azhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcTQUbimVsO7p7wRuyYZSNKei7erJoiKLzcwQ3eoY=s64","userId":"00085534427974934913"}},"outputId":"f5fc3d4f-fc45-42e2-c167-1c84dbb426d5"},"source":["#Head of the Vocab file: Line nums indicate index of vocab\n","!head -n10 {model_prefix}.vocab | nl"],"execution_count":7,"outputs":[{"output_type":"stream","text":["head: cannot open 'sp.vocab' for reading: No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JGokJB_XZ5Ch","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"error","timestamp":1600704280095,"user_tz":-360,"elapsed":2754,"user":{"displayName":"ibrahim al azhar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhcTQUbimVsO7p7wRuyYZSNKei7erJoiKLzcwQ3eoY=s64","userId":"00085534427974934913"}},"outputId":"26d3f74e-f595-4dff-fbca-bdf40a71ad3b"},"source":["## load up the Processor\n","# SentencePiece allows us to make a purely end-to-end system that does not depend on languge-specific pre/postprocessing\n","sp = spm.SentencePieceProcessor() # SentencePiece is an unsupervised text tokenizer and detokenizer mainly for NN based text genertion systems where the vocabulary size is predetermined prior to the neural model training.\n","sp.load(f'{model_prefix}.model')"],"execution_count":8,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-892a1260a555>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# SentencePiece allows us to make a purely end-to-end system that does not depend on languge-specific pre/postprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentencePieceProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# SentencePiece is an unsupervised text tokenizer and detokenizer mainly for NN based text genertion systems where the vocabulary size is predetermined prior to the neural model training.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{model_prefix}.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sentencepiece.py\u001b[0m in \u001b[0;36mLoad\u001b[0;34m(self, model_file, model_proto)\u001b[0m\n\u001b[1;32m    365\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmodel_proto\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadFromSerializedProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sentencepiece.py\u001b[0m in \u001b[0;36mLoadFromFile\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_sentencepiece\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentencePieceProcessor_LoadFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     def Init(self,\n","\u001b[0;31mOSError\u001b[0m: Not found: \"sp.model\": No such file or directory Error #2"]}]},{"cell_type":"code","metadata":{"id":"lF3BqKVsaOrq","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}